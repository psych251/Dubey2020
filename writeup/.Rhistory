---
title: "Reproducibility Report for Experiment 1 by Rachit Dubey & Thomas L. Griffiths (2020, Psychological Review)"
author: "Xi Jia Zhou (xijiazho@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
html_document:
toc: yes
toc_depth: 3
toc_float:
collapsed: false
---
<!-- Reproducibility reports should all use this template to standardize reporting across projects. These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->
## Introduction
**Clarify key analysis of interest here**  You can also pre-specify additional analyses you plan to do.
### Justification for choice of study
I am a first year PhD student in Stanford Graduate School of Education. I work with Professor Nick Haber in Stanford Autonomous Agents Lab. My research interests are broadly around curiosity, social learning and causal learning. Particularly, one of my research interests is to understand the different motivations behind curiosity, such as the motivation to gain optimal predictability (causal learning about the world) and to belong to a social group (a social motivation). In this paper which I chose, the first experiment and its result is relevant to my research interest. The result showed that people's curiosity, as a function of confidence, manipulated by how frequent the stimuli were shown, can be either an inverted U-shaped curve, or a decreasing line. Therefore, people's curiosity can be manipulated to be maximized either when the stimuli are moderately complex or when the stimuli are the most novel, depending on the environmental structure of how frequent past stimuli are shown and what future stimuli are.
### Anticipated challenges
The stimuli are 40 trivia questions that are about different topics, such as animals and books. They are originally published at Kang et al.(2009)'s first experiment. I will need to make the study on a website and deliver it to online participants through Prolific or MTurk. A potential challenge is to create or collect the stimuli myself and write the website using Javascript and PHP. I haven't written a study using Javascript and PHP before. The authors didn't put their stimuli and codes publicly accessible in an OSF repository.
### Links
Project repository (on Github): https://github.com/psych251/Dubey2020.
Original paper (as hosted in your repo): https://github.com/psych251/Dubey2020/tree/main/original_paper.
## Methods
### Description of the steps required to reproduce the results
Please describe all the steps necessary to reproduce the key result(s) of this study.
### Differences from original study
Explicitly describe known differences in the analysis pipeline between the original paper and yours (e.g., computing environment). The goal, of course, is to minimize those differences, but differences may occur. Also, note whether such differences are anticipated to influence your ability to reproduce the original results.
## Project Progress Check 1
### Measure of success
Please describe the outcome measure for the success or failure of your reproduction and how this outcome will be computed.
### Pipeline progress
Earlier in this report, you described the steps necessary to reproduce the key result(s) of this study. Please describe your progress on each of these steps (e.g., data preprocessing, model fitting, model evaluation).
## Results
### Data preparation
Data preparation following the analysis plan.
```{r include=F}
### Data Preparation
#### Load Relevant Libraries and Functions
#### Import data
#### Data exclusion / filtering
#### Prepare data for analysis - create columns etc.
```
### Key analysis
The analyses as specified in the analysis plan.
*Side-by-side graph with original graph is ideal here*
###Exploratory analyses
Any follow-up analyses desired (not required).
## Discussion
### Summary of Reproduction Attempt
Open the discussion section with a paragraph summarizing the primary result from the key analysis and assess whether you successfully reproduced it, partially reproduced it, or failed to reproduce it.
### Commentary
Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis of the dataset, (b) assessment of the meaning of the successful or unsuccessful reproducibility attempt - e.g., for a failure to reproduce the original findings, are the differences between original and present analyses ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the reproducibility attempt (if you contacted them).  None of these need to be long.
