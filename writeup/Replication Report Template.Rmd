---
title: "Replication of Experiment 1 by Rachit Dubey & Thomas L. Griffiths (2020, Psychological Review)"
author: "Xi Jia Zhou (xijiazho@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

I am a first year PhD student in Stanford Graduate School of Education, working with Professor Nick Haber in Stanford Autonomous Agents Lab. My research interests are broadly around curiosity, social learning and causal learning. Particularly, one of my research interests is to understand the different motivations behind curiosity, such as the motivation to gain optimal predictability (causal learning about the world) and to belong to a social group (a social motivation). In this chosen paper, the first experiment and its result is relevant to my research interest. The result showed that people's curiosity, as a function of confidence, manipulated by how frequent the stimuli were shown, can be either an inverted U-shaped curve, or a decreasing line. Therefore, people's curiosity can be manipulated to peak either when they see stimluli that are moderately complex or when they see stimuli that are the most novel, depending on the environmental structures of how frequent past stimuli are shown and whether future stimuli will be chosen from past stimuli.

The stimuli are 40 trivia questions that are about different topics, such as animals and books. They are originally published at Kang et al.(2009)'s first experiment. I will need to build the web-based study and deliver it to online participants through Prolific or MTurk. A potential challenge is to create or collect the stimuli myself and write the website using Javascript and PHP. I haven't written a study using these programming languages before. The authors didn't have their stimuli and experiment codes publicly accessible in a public repository. 

Project repository (on Github): https://github.com/psych251/Dubey2020.
Original paper (as hosted in your repo): https://github.com/psych251/Dubey2020/tree/main/original_paper.

## Methods
### Power Analysis

Original effect size, power analysis for samples to achieve 80%, 90%, 95% power to detect that effect size.  Considerations of feasibility for selecting planned sample size.

### Planned Sample

Planned sample size and/or termination rule, sampling frame, known demographics if any, preselection rules if any.
- Will probably use the same sample size. More to be determined.

### Materials

The same materials will be used from the original study: "The stimuli used in the experiment were 40 trivia questions on various topics that were taken directly from Experiment 1 in Kang et al. (2009). According to the authors, these questions were designed to measure curiosity about semantic knowledge and evoke a range of curiosity levels."

### Procedure	

The same procedure will be used from the original study: "The experiment was divided into three phases – Phase 1, Phase 2, and Phase 3. In Phase 1, participants were shown 40 trivia questions one after another and were asked to rate their confidence (i.e., probability that they know the correct answer) and curiosity in knowing the correct answer. Curiosity ratings were on a scale from 1 to 7 and the confidence scale ranged from 0 to 100%. The order of trivia questions was randomized for each participant. Note that Phase 1 of our experiment followed the procedure of Kang et al.’s design closely. This part of the experiment took approximately 7-8 minutes to complete.

In Phase 2, all previous 40 questions from Phase 1 were again shown one after another and
participants had the choice to reveal the answer to those questions. However, each time participants chose to reveal an answer, they had to wait an extra 10 seconds for the next question to appear. 

Findings from Experiment 3 of Kang et al., (2009) showed that participants were more likely to spend time, to wait longer, for the answers that they were more curious about. Thus, requiring participants to spend time to obtain information served as a proxy to measure their curiosity.

In Phase 3, participants were shown 10 out of the previously shown 40 questions and were
given the chance to answer these 10 questions. For each correct answer, participants were given a bonus of $0.08. To discourage participants from using Google or other search engines, they were only given 2 minutes in total to answer the questions.

At the beginning of the experiment, participants were randomly assigned to two conditions –the confidence and the uniform condition. These conditions differed in the way the 10 questions were sampled in Phase 3 and apart from that, the two conditions were exactly the same. In the confidence condition, the sampling in Phase 3, was done based on the confidence ratings provided by the participants i.e. the questions for which participant’s confidence rating was higher were more likely to appear in Phase 3. In the uniform condition, this sampling procedure was completely random i.e. each question was equally likely to appear in Phase 3. Importantly, participants were informed about the sampling procedure for their respective condition before the beginning of Phase 2. The confidence condition thus creates a situation in which confidence is related to probability of occurrence and the uniform condition breaks this relationship. To ensure that participants understood the sampling procedure, participants had to answer a multiple-choice question about the sampling procedure after the instructions for Phase 2 were shown to them. If they gave an incorrect answer, participants were shown the instructions again and had to re-answer the question (this process was repeated until they answered the question correctly)."

### Analysis Plan

Can also quote directly, though it is less often spelled out effectively for an analysis strategy section.  The key is to report an analysis strategy that is as close to the original - data cleaning rules, data exclusion rules, covariates, etc. - as possible.  

**Clarify key analysis of interest here**  You can also pre-specify additional analyses you plan to do.

### Differences from Original Study

Explicitly describe known differences in sample, setting, procedure, and analysis plan from original study.  The goal, of course, is to minimize those differences, but differences will inevitably occur.  Also, note whether such differences are anticipated to make a difference based on claims in the original article or subsequent published research on the conditions for obtaining the effect.

### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


## Results
### Data preparation

Data preparation following the analysis plan.
	
```{r include=F}
###Data Preparation

####Load Relevant Libraries and Functions

####Import data

#### Data exclusion / filtering

#### Prepare data for analysis - create columns etc.
```

### Confirmatory analysis

The analyses as specified in the analysis plan.  

*Side-by-side graph with original graph is ideal here*

###Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion
### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
